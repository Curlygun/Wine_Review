{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=\"The weather seems good today. Yesterday it seemed hot. The new marvel movie is postponed due to the lockdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'weather', 'seems', 'good', 'today', '.', 'Yesterday', 'it', 'seemed', 'hot', '.', 'The', 'new', 'marvel', 'movie', 'is', 'postponed', 'due', 'to', 'the', 'lockdown', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "print(word_tokenize(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'concordance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-84b753df8510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcordance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'concordance'"
     ]
    }
   ],
   "source": [
    "a.concordance(\"The\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Mr. Smith, how are you doing today?', 'The weather is great, and Python is awesome.', 'The sky is pinkish-blue.', \"You shouldn't eat cardboard.\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "EXAMPLE_TEXT = \"Hello Mr. Smith, how are you doing today? The weather is great, and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard.\"\n",
    "\n",
    "print(sent_tokenize(EXAMPLE_TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "a= \" The is have , Phalgun a and if Great\"\n",
    "l = word_tokenize(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      ",\n",
      "Phalgun\n",
      "Great\n"
     ]
    }
   ],
   "source": [
    "z = stopwords.words('english')\n",
    "for i in l:\n",
    "    if i not in z:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['genius', 'mastermind', 'brain', 'brainiac', 'Einstein', 'brilliance', 'genius', 'ace', 'adept', 'champion', 'sensation', 'maven', 'mavin', 'virtuoso', 'genius', 'hotshot', 'star', 'superstar', 'whiz', 'whizz', 'wizard', 'wiz', 'genius', 'wizardry', 'flair', 'genius']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "synonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"genius\"):\n",
    "    for lm in syn.lemmas():\n",
    "             synonyms.append(lm.name())\n",
    "print ((synonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unhappy'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"happy\"):\n",
    "    for lm in syn.lemmas():\n",
    "        if lm.antonyms():\n",
    "            antonyms.append(lm.antonyms()[0].name())\n",
    "\n",
    "print(set(antonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"winereview.csv\")\n",
    "from inltk.inltk import get_similar_sentences\n",
    "\n",
    "# get similar sentences to the one given in hindi\n",
    "output = get_similar_sentences('मैं आज बहुत खुश हूं', 5, 'hi')\n",
    "\n",
    "print(output)\n",
    "\n",
    "from inltk.inltk import tokenize\n",
    "hindi_text = \"\"\"प्राचीन काल में विक्रमादित्य नाम के एक आदर्श राजा हुआ करते थे।\n",
    "अपने साहस, पराक्रम और शौर्य के लिए  राजा विक्रम मशहूर थे। \n",
    "ऐसा भी कहा जाता है कि राजा विक्रम अपनी प्राजा के जीवन के दुख दर्द जानने के लिए रात्री के पहर में भेष बदल कर नगर में घूमते थे।\"\"\"\n",
    "# tokenize(input text, language code)\n",
    "tokenize(hindi_text,'hi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
